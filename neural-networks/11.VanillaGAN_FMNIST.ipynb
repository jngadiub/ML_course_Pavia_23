{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jngadiub/ML_course_Pavia_23/blob/main/neural-networks/11.VanillaGAN_FMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating FashionMNIST data using Vanilla GAN with PyTorch\n",
        "\n",
        "Adapted from [this](https://debuggercafe.com/vanilla-gan-pytorch/) blog.\n",
        "\n",
        "In this tutorial, we will generate the digit images from the FashionMNIST dataset using vanilla GAN. We will use the PyTorch deep learning framework to build and train the Generative Adversarial Network.\n",
        "\n",
        "## Recap of vanilla GANs\n",
        "\n",
        "GANs contail two neural networks in their architecture. One is the **generator** and the other one is the **discriminator**.\n",
        "\n",
        "While training a GAN, the generator tries to generate new fake data from a given noisy sample space. And with each iteration, it tries to generate more and more realistic data.\n",
        "\n",
        "At the same time, the discriminator tries to differentiate the real data from the generated fake data of the generator. While training the discriminator, we provide it with both, the **real data (positive examples)** and the **generated data (negative examples)**. A time will come when the discriminator won’t be able to tell whether the data is real or fake (generated by the generator). This is the time we stop the training and can successfully use the generator to generate realistic data that resembles the input data.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://raw.githubusercontent.com/jngadiub/ML_course_Pavia_23/main/neural-networks/gan-arch.png\" width=\"800\"/>\n",
        "</div>\n",
        "\n",
        "In vanilla GAN from the [original paper by Goodfellow et al. (2014)](https://arxiv.org/abs/1406.2661) the loss function is the standard binary cross entropy.\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\theta^{(G)},\\theta^{(D)}) = \\mathbb{E}_{x}\\log D(x) + \\mathbb{E}_{z}(1-D(G(z)))\n",
        "$$\n",
        "\n",
        "* $\\mathbb{E}_x$ is the expected value over all the data instances. You may recognize this as taking a sample from all the real images.\n",
        "* $\\mathbb{E}_z$ is the expected value over the latent vector or the random noise vector that we give as input to the generator.\n",
        "* $D(x)$ corresponds to the probability by the discriminator that the given data $x$ is real.\n",
        "* $G(z)$ is the data generated by the generator when we give it $z$ as the input.\n",
        "* $D(G(z))$ is the probability by the discriminator that the data generated by the generator $G(z)$ is real.\n",
        "\n",
        "In GAN training, optimizing the above loss function is a two-sum game for the generator and the discriminator. It is called also **minimax** because the discriminator tries to maximize the $\\log D(x)$ term. While at the same time, the generator tries to minimize the $\\log(1-D(G(z)))$ term."
      ],
      "metadata": {
        "id": "Tp2zf8CWYoRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and train the GAN\n",
        "\n",
        "### Modules import\n",
        "\n",
        "The first step is to import all the modules and libraries that we will need, of course."
      ],
      "metadata": {
        "id": "t8MzYek3FbUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import imageio\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "\n",
        "from torchvision.utils import make_grid, save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "matplotlib.style.use('ggplot')"
      ],
      "metadata": {
        "id": "sJLViIQXFwKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Among all the known modules, we are also importing the `make_grid` and `save_image` functions from `torchvision.utils`. These two functions will help us save PyTorch tensor images in a very effective and easy manner without much hassle."
      ],
      "metadata": {
        "id": "IJH40grSF4dX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG4Ii5D7Wpy_"
      },
      "source": [
        "# we need input and output folders to locally save the dataset and to save the output model\n",
        "!mkdir input\n",
        "!mkdir outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperpars definition\n",
        "\n",
        "Let's define the learning parameters for our generative adversarial network. You should now be familiar with most except for:\n",
        "\n",
        "* `nz`: This is the latent vector or the noise vector size. The input feature size for the generator is going to be the same as this latent vector size.\n",
        "* `sample_size` the number of fake images to be generated by the generator from the fixed-size noise vector.\n",
        "* `k`: the number of gradient descent steps for the discriminator before one step for the generator is taken\n",
        "\n"
      ],
      "metadata": {
        "id": "mjHAooxPFpem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#learning parameters\n",
        "batch_size = 512\n",
        "epochs = 200\n",
        "sample_size = 64 # fixed sample size\n",
        "nz = 128 # latent vector size\n",
        "k = 1 # number of steps to apply to the discriminator\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "rV0icNQlZyVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and inspect dataset\n",
        "\n",
        "We will define the dataset transforms first. The following block of code defines the image transforms that we need for the MNIST dataset."
      ],
      "metadata": {
        "id": "-YMzm3xqHfS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,)),\n",
        "])\n",
        "\n",
        "to_pil_image = transforms.ToPILImage()"
      ],
      "metadata": {
        "id": "YZ1KEkxTZ2ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* first we define transform which will convert the image to tensors and normalizes them as well\n",
        "* second, the `to_pil_image` will convert the images from PyTorch tensors to the `PIL` (Python Image Library) image format for standard python libraries to be digested."
      ],
      "metadata": {
        "id": "yLIaB2eTHhif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next block of code defines the training dataset and training data loader. We will download the FashionMNIST dataset using the dataset module from `torchvision`."
      ],
      "metadata": {
        "id": "5kTJ9K2SIrKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "    root='input/data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "wB1--VS_Z4Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at where data were saved:"
      ],
      "metadata": {
        "id": "MYZ20p9eIy6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls input/data/FashionMNIST/raw"
      ],
      "metadata": {
        "id": "jlFHi-CCb8_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's plot a few images from the dataset:"
      ],
      "metadata": {
        "id": "UsYKX74YI1rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(images, labels, classes, nimages=4):\n",
        "    fig, axs = plt.subplots(1, nimages, figsize=(10, 5))\n",
        "    for i in range(nimages):  \n",
        "        image = images[i]\n",
        "        axs[i].imshow(image.numpy().squeeze(), cmap='gray')\n",
        "        axs[i].set_title(classes[labels[i]])\n",
        "        axs[i].axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NXwjPGZXcDCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = enumerate(train_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "example_data.shape"
      ],
      "metadata": {
        "id": "b5RlFejAgnbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = train_data.classes\n",
        "show_images(example_data, example_targets, classes)"
      ],
      "metadata": {
        "id": "lkNuQUzPg002"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is all that we need regarding the dataset. In the following two sections, we will define the generator and the discriminator network of Vanilla GAN."
      ],
      "metadata": {
        "id": "z93jmopJI52C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Generator Neural Network\n",
        "\n",
        "Let’s start with building the generator neural network.\n",
        "\n",
        "It is going to be a very simple network with `Linear` layers, and `LeakyReLU` activations in-between."
      ],
      "metadata": {
        "id": "7UQrxbvtJdhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz):\n",
        "        super(Generator, self).__init__()\n",
        "        self.nz = nz\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(self.nz, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Linear(1024, 784),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x).view(-1, 1, 28, 28)"
      ],
      "metadata": {
        "id": "CLaEVQdcZ66H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have the `__init__()` function which accepts the `nz` parameter which is going to be the number of input features for the first linear layer of the generator network.\n",
        "\n",
        "We are using the `Sequential` container to build the neural network.\n",
        "The first linear layer has `in_features` equal to `nz`, that is equal to `128`. The `out_features` is equal to `256`. Then we have a `LeakyReLU `activation with negative slope of `0.2`.\n",
        "We have a total of four `Linear` layers and three `LearkyReLU` activations. The last layer’s activation is `Tanh`.\n",
        "\n",
        "Then we have the `forward()` function which does a forward pass of the batch of images through the neural network. It returns the outputs after reshaping them into `batch_size x 1 x 28 x 28`."
      ],
      "metadata": {
        "id": "8sn3uSFBJpG4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Discriminator Neural Network\n",
        "\n",
        "Here we will define the discriminator neural network.\n",
        "\n",
        "Remember that the discriminator is a binary classifier. Therefore, we will have to take that into consideration while building the discriminator neural network."
      ],
      "metadata": {
        "id": "BYEtJmCnKiPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.n_input = 784\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(self.n_input, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        return self.main(x)"
      ],
      "metadata": {
        "id": "q20bFBoIZ9Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* we define `self.n_input = 784` which is the flattened size of the MNIST images (28×28). This is going to be the `in_feature` for the first layer.\n",
        "* we define the discriminator network using the `Sequential` container. Here, we use `Linear` layers and `LeakyReLU` activations as well. Along with that, we use `Dropout` with rate of 0.3 after the first three `Linear` layers.\n",
        "* we are using the `Sigmoid` activation after the last `Linear` layer.\n",
        "* the `forward()` function makes a forward pass of the data through the discriminator network. It returns the binary classification of whether an image is fake or real (0 or 1)."
      ],
      "metadata": {
        "id": "VQekCTkpKqqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the full model"
      ],
      "metadata": {
        "id": "F1R11dkPLGQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator(nz).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "print('##### GENERATOR #####')\n",
        "print(generator)\n",
        "print('######################')\n",
        "\n",
        "print('\\n##### DISCRIMINATOR #####')\n",
        "print(discriminator)\n",
        "print('######################')\n",
        "\n",
        "# optimizers\n",
        "optim_g = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "optim_d = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "\n",
        "# loss function\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "BrLOA7nQaHC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note that we are passing the nz (the noise vector size) as an argument while initializing the generator network.*"
      ],
      "metadata": {
        "id": "NmJaBox3LOdX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some utility functions\n",
        "\n",
        "While training the generator and the discriminator, we need to store the epoch-wise loss values for both the networks. We will define two lists for this task. We will also need to store the images that are generated by the generator after each epoch. For that also, we will use a list."
      ],
      "metadata": {
        "id": "eJaobtIoLSLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses_g = [] # to store generator loss after each epoch\n",
        "losses_d = [] # to store discriminator loss after each epoch\n",
        "images = [] # to store images generatd by the generator"
      ],
      "metadata": {
        "id": "BVwnyYn8aJ4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For training the GAN in this tutorial, we need the real image data and the fake image data from the generator. To calculate the loss, we also need real labels and the fake labels. Those will have to be tensors whose size should be equal to the batch size.\n",
        "\n",
        "Let’s define two functions, which will create tensors of 1s (ones) and 0s (zeros) for us whose size will be equal to the batch size."
      ],
      "metadata": {
        "id": "2PRD6BUFLbZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to create real labels (1s)\n",
        "def label_real(size):\n",
        "    data = torch.ones(size, 1)\n",
        "    return data.to(device)\n",
        "\n",
        "# to create fake labels (0s)\n",
        "def label_fake(size):\n",
        "    data = torch.zeros(size, 1)\n",
        "    return data.to(device)"
      ],
      "metadata": {
        "id": "mkmkoqq8Lhfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For generating fake images, we need to provide the generator with a noise vector. The size of the noise vector should be equal to `nz` (128) that we have defined earlier. To create this noise vector, we can define a function called `create_noise()`."
      ],
      "metadata": {
        "id": "Tjcz0k58Li2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create the noise vector\n",
        "def create_noise(sample_size, nz):\n",
        "    return torch.randn(sample_size, nz).to(device)"
      ],
      "metadata": {
        "id": "7voi9OX3Lo0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is one final utility function. We need to save the images generated by the generator after each epoch. Now, they are torch tensors. To save those easily, we can define a function which takes those batch of images and saves them in a grid-like structure."
      ],
      "metadata": {
        "id": "1gTCiDQxLv6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to save the images generated by the generator\n",
        "def save_generator_image(image, path):\n",
        "    save_image(image, path)"
      ],
      "metadata": {
        "id": "tB2xVSH8aMtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train functions\n",
        "\n",
        "First, we will write the function to train the discriminator, then we will move into the generator part.\n",
        "\n",
        "Let’s write the code first, then we will move onto the explanation part."
      ],
      "metadata": {
        "id": "DOZIIrprLzyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the discriminator network\n",
        "def train_discriminator(optimizer, data_real, data_fake):\n",
        "    b_size = data_real.size(0)\n",
        "    real_label = label_real(b_size)\n",
        "    fake_label = label_fake(b_size)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output_real = discriminator(data_real)\n",
        "    loss_real = criterion(output_real, real_label)\n",
        "\n",
        "    output_fake = discriminator(data_fake)\n",
        "    loss_fake = criterion(output_fake, fake_label)\n",
        "\n",
        "\n",
        "    loss_real.backward()\n",
        "    loss_fake.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss_real + loss_fake"
      ],
      "metadata": {
        "id": "yEzftR3daRTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* we get the batch size of the data. Then we use the batch size to create the fake and real labels.\n",
        "* before doing any training, we first set the gradients to zero\n",
        "* we get the `output_real` by doing a forward pass of the real data (`data_real`) through the discriminator. We calculates the loss for the real outputs and the real labels.\n",
        "* we get fake outputs using fake data and calculate the loss for the fake outputs and the fake labels.\n",
        "* we backpropagate the gradients for the fake and the real loss and update the parameters as well\n",
        "* we return the total loss for the discriminator network."
      ],
      "metadata": {
        "id": "srARFATKMFOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will write the code to train the generator. This is going to a bit simpler than the discriminator coding."
      ],
      "metadata": {
        "id": "P3GdkhNFMdZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the generator network\n",
        "def train_generator(optimizer, data_fake):\n",
        "    b_size = data_fake.size(0)\n",
        "    real_label = label_real(b_size)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = discriminator(data_fake)\n",
        "    loss = criterion(output, real_label)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss   "
      ],
      "metadata": {
        "id": "GdgMMNyXaTYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* we get the batch size and then create the real labels. Remember that the fake data is actually real for the generator. Therefore, we are using real labels (ones) for training the generator network.\n",
        "* we set the gradients to zero.\n",
        "* we pass the fake data through the discriminator and get the outputs then we calculate the loss using the outputs and the real labels -- remember that the generator only generates fake data and it improves after each iteration by taking in the feedback from the discriminator.\n",
        "* we backpropagate the gradients.\n",
        "* we update the generator parameters and not the discriminator parameters. Because in this step, we want the generator to learn, not the discriminator. The optimizer parameter in the function definition is the `optim_g` that we will pass as the argument while calling the function."
      ],
      "metadata": {
        "id": "qZSuAkGkMggM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train full GAN model\n",
        "\n",
        "In this section, we will write the code to train the GAN for some epochs.\n",
        "\n",
        "First, let’s create the noise vector that we will need to generate the fake data using the generator network."
      ],
      "metadata": {
        "id": "w-O3i3VQMxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the noise vector\n",
        "noise = create_noise(sample_size, nz)"
      ],
      "metadata": {
        "id": "GU-pgjTJaVM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is also a good idea to switch both the networks to training mode before moving ahead."
      ],
      "metadata": {
        "id": "dn4yFxhJM5Cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator.train()\n",
        "discriminator.train()"
      ],
      "metadata": {
        "id": "o7eMl4NaM7v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use a simple `for` loop for training our generator and discriminator networks for some epochs."
      ],
      "metadata": {
        "id": "h1n_SZ5dM-yi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqKLmvRJVnc3"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    loss_g = 0.0\n",
        "    loss_d = 0.0\n",
        "    for bi, data in tqdm(enumerate(train_loader), total=int(len(train_data)/train_loader.batch_size)):\n",
        "        image, _ = data\n",
        "        image = image.to(device)\n",
        "        b_size = len(image)\n",
        "        # run the discriminator for k number of steps\n",
        "        for step in range(k):\n",
        "            data_fake = generator(create_noise(b_size, nz)).detach()\n",
        "            data_real = image\n",
        "            # train the discriminator network\n",
        "            loss_d += train_discriminator(optim_d, data_real, data_fake)\n",
        "        data_fake = generator(create_noise(b_size, nz))\n",
        "        # train the generator network\n",
        "        loss_g += train_generator(optim_g, data_fake)\n",
        "\n",
        "    # create the final fake image for the epoch\n",
        "    generated_img = generator(noise).cpu().detach()\n",
        "    # make the images as grid\n",
        "    generated_img = make_grid(generated_img)\n",
        "    # save the generated torch tensor models to disk\n",
        "    save_generator_image(generated_img, f\"outputs/gen_img{epoch}.png\")\n",
        "    images.append(generated_img)\n",
        "    epoch_loss_g = loss_g / bi # total generator loss for the epoch\n",
        "    epoch_loss_d = loss_d / bi # total discriminator loss for the epoch\n",
        "    losses_g.append(epoch_loss_g)\n",
        "    losses_d.append(epoch_loss_d)\n",
        "    \n",
        "    print(f\"Epoch {epoch} of {epochs}\")\n",
        "    print(f\"Generator loss: {epoch_loss_g:.8f}, Discriminator loss: {epoch_loss_d:.8f}\")\n",
        "\n",
        "print('DONE TRAINING')\n",
        "torch.save(generator.state_dict(), 'outputs/generator.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* we define `loss_g` and `loss_d` to keep track of the batch-wise loss values for the discriminator and the generator.\n",
        "* we iterate through the batches. We only need the image data. Therefore, we get the images and load them to the computation device. And we calculate the batch size.\n",
        "* we run the discriminator for $k$ number of steps. And remember that for our purpose we have defined $k = 1$. This is the least expensive option as this will train one step of the discriminator and one step of the generator. You can play around with the value of $k$. But remember that the computation time will also increase with an increase in the value of $k$. Note that we are passing the discriminator optimizer while calling `train_discriminator()`.\n",
        "* we again create a new noise vector. This we pass as an argument along with the generator optimizer while calling `train_generator()`.\n",
        "* we create the final fake images for the current epoch and load them onto the CPU so that we can save them to the disk. We make a grid of those images.\n",
        "* we save the generated images to disk and append those images to the images list.\n",
        "* Finally, we calculate the epoch-wise loss of the generator and the discriminator and print those loss values."
      ],
      "metadata": {
        "id": "jQppz9lYNFkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the generated images as GIF file\n",
        "imgs = [np.array(to_pil_image(img)) for img in images]\n",
        "imageio.mimsave('outputs/generator_images.gif', imgs)\n",
        "\n",
        "losses_g_cpu = [l.cpu().detach().numpy() for l in losses_g]\n",
        "losses_d_cpu = [l.cpu().detach().numpy() for l in losses_d]\n",
        "plt.figure()\n",
        "plt.plot(losses_g_cpu, label='Generator loss')\n",
        "plt.plot(losses_d_cpu, label='Discriminator Loss')\n",
        "plt.legend()\n",
        "plt.savefig('outputs/loss.png')"
      ],
      "metadata": {
        "id": "iE2t-eX4abRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that for the first few epochs the loss values of the generator are increasing and the discriminator losses are decreasing. This is because **during the initial phases the generator does not create any good fake images. The discriminator easily classifies between the real images and the fake images**. As the training progresses, the generator slowly starts to generate more believable images. At this time, the discriminator also starts to classify some of the fake images as real. Therefore, the generator loss begins to decrease and the discriminator loss begins to increase.\n",
        "\n",
        "Also, we can clearly see that training for more epochs will surely help.\n",
        "\n",
        "Now, let’s look at the generated images."
      ],
      "metadata": {
        "id": "Vy8pDakXtvjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls outputs"
      ],
      "metadata": {
        "id": "1ns8q1YZuBkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "from IPython.display import display\n",
        "image_paths = ['outputs/gen_img0.png','outputs/gen_img99.png','outputs/gen_img199.png']\n",
        "display(Image(filename=image_paths[0]), Image(filename=image_paths[1]), Image(filename=image_paths[2]))"
      ],
      "metadata": {
        "id": "oi5mJIiixO7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's look at the animation!"
      ],
      "metadata": {
        "id": "BZbs3ph4Tbfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "from IPython.display import display\n",
        "\n",
        "# Replace 'path/to/your-gif.gif' with the path to your local GIF file\n",
        "gif_path = 'outputs/generator_images.gif'\n",
        "\n",
        "# Display the GIF\n",
        "with open(gif_path, 'rb') as f:\n",
        "    display(Image(data=f.read(), format='gif'))\n"
      ],
      "metadata": {
        "id": "7huuwj5eTWbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional excercise\n",
        "\n",
        "Modify the code to use the JS and Wasserstein distances and compare.\n"
      ],
      "metadata": {
        "id": "3_aHx_w6TeO6"
      }
    }
  ]
}